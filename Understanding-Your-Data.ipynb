{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"eb03ad8a-3a34-4951-a4f0-02afc1c4d359","cell_type":"markdown","source":"# ğŸ§  `Understanding Your Data`\n\nBefore jumping into model building, one of the most critical stages in any machine learning project is **understanding your data**.  \nThis step lays the foundation for every decision that follows â€” from preprocessing and feature selection to model choice and evaluation.\n\n---\n\n## ğŸ¯ Why Understanding Data Matters\n\nUnderstanding your dataset helps you:\n\n- Detect **data quality issues early** (missing values, duplicates, inconsistencies)  \n- Choose appropriate **feature engineering** and **modeling techniques**  \n- Avoid misleading results due to **data leakage or bias**  \n- Save time by identifying **irrelevant or redundant features** before training  \n\nğŸ’¡ **Fact:** In real-world ML projects, data understanding and cleaning can take up to **60â€“80%** of total project time â€” because the quality of your data directly defines the quality of your model.\n\n---\n\n## ğŸ” Key Questions to Ask About Your Data\n\nBelow are essential questions every ML engineer should ask before modeling â€” along with *why they matter*:\n\n---\n\n### 1ï¸âƒ£ How big is the data?\n\n**Why it matters:** Dataset size determines which algorithms and validation methods are feasible.  \n**Insight:** A small dataset might require data augmentation or simpler models, while large datasets demand efficient storage, sampling, and computation strategies.\n\n---\n\n### 2ï¸âƒ£ How does the data look?\n\n**Why it matters:** Viewing sample rows gives a sense of structure, column names, and potential anomalies.  \n**Action:** Use `.head()`, `.tail()`, or `.sample()` in Pandas to inspect random records.  \n**Fact:** Early visual inspection often reveals typos, inconsistent entries, or unexpected symbols.\n\n---\n\n### 3ï¸âƒ£ What is the data type of each column?\n\n**Why it matters:** Correct data types (numeric, categorical, datetime, object) are crucial for preprocessing and model compatibility.  \n**Action:** Use `.info()` or `.dtypes` to check types and memory usage.  \n**Tip:** Convert datatypes carefully â€” wrong conversions can cause model errors or performance loss.\n\n---\n\n### 4ï¸âƒ£ Are there any missing values?\n\n**Why it matters:** Missing data can bias results and reduce model accuracy.  \n**Action:** Use `.isnull().sum()` to find missing values.  \n**Solution:** Handle them using imputation (mean, median, mode), interpolation, or removal based on data context.\n\n---\n\n### 5ï¸âƒ£ How does the data look mathematically?\n\n**Why it matters:** Understanding basic statistics helps detect outliers, skewness, or scaling issues.  \n**Action:** Use `.describe()` or visualizations (histograms, boxplots).  \n**Fact:** Skewed data may require transformation (e.g., log or power scaling) before model training.\n\n---\n\n### 6ï¸âƒ£ Are there duplicate values?\n\n**Why it matters:** Duplicates inflate data and can bias models during training.  \n**Action:** Use `.duplicated().sum()` to check for them and remove using `.drop_duplicates()`.  \n**Fact:** Even small amounts of duplication can distort model metrics like accuracy or recall.\n\n---\n\n### 7ï¸âƒ£ How is the correlation between columns?\n\n**Why it matters:** Highly correlated features can cause **multicollinearity**, confusing models and inflating variance.  \n**Action:** Use `.corr()` or heatmaps (Seaborn/Matplotlib) to visualize relationships.  \n**Tip:** Drop or combine highly correlated features to simplify the model.\n\n---\n\n## ğŸ“Š Summary\n\nUnderstanding your data is **not just an initial step** â€” itâ€™s an **ongoing process** throughout model development.  \nIt ensures your insights are **trustworthy**, your features are **meaningful**, and your models are **robust**.\n\n> ğŸ§© **In short:** The better you know your data, the smarter your model will be.\n","metadata":{}},{"id":"d6233b25-1fd4-4b89-b8d2-f257de7f5bbf","cell_type":"markdown","source":"# ğŸ§  `Exploratory Data Analysis (EDA) using Univariate Analysis`\n\n---\n\n## ğŸ“Š Introduction to Data\n\nIn the world of **Data Science**, everything starts with **data**.  \nData is a **collection of facts and statistics** that can be analyzed to gain insights and make informed decisions.\n\nIn simple terms:\n **Data = Raw Information**\n\n### ğŸ”¹ Types of Data\n\nData is broadly divided into two main categories:\n\n1. **Numerical Data (Quantitative)**  \n   - Represents measurable quantities or numbers.  \n   - Example: Age, Salary, Temperature, Height.  \n   - Can be further divided into:\n     - **Continuous Data** â†’ Values within a range (e.g., 5.3, 6.7)\n     - **Discrete Data** â†’ Countable values (e.g., 1, 2, 3)\n\n2. **Categorical Data (Qualitative)**  \n   - Represents labels, groups, or categories.  \n   - Example: Gender (Male/Female), Country (USA, UK, Pakistan), Product Type (A, B, C)\n\nğŸ’¡ **Fun Fact:**  \nOver 70% of the time in any Data Science project is spent **understanding, cleaning, and exploring data**, not modeling!\n\n---\n\n## ğŸ” What is Univariate Analysis?\n\n**Univariate Analysis** means analyzing **one variable at a time**.  \nIt helps us **understand the pattern, distribution, and behavior** of individual features in the dataset.\n\n### ğŸ¯ Purpose:\n- To summarize data.\n- To detect outliers or unusual patterns.\n- To decide which features may be useful for modeling.\n\n### âš™ï¸ How we do it:\n- For **Numerical Data** â†’ we use plots like **histogram**, **box plot**, **displot**, etc.  \n- For **Categorical Data** â†’ we use **count plots**, **bar charts**, or **pie charts**.\n\nğŸ’¡ **Fun Fact:**  \nThe word *â€œUnivariateâ€* comes from â€œUniâ€ meaning one, and â€œVariateâ€ meaning variable â€” literally \"one variable analysis\"!\n\n---\n\n## `ğŸ§° Libraries Commonly Used in EDA`\n\nBefore jumping into plots, letâ€™s discuss the libraries that help us perform EDA effectively.\n\n### ğŸ“¦ `pandas`\n- **Purpose:** Used for data manipulation and analysis.\n- **Logic:** Think of it as Excel in Python â€” it allows you to read, clean, and explore data easily.\n- **Key Structure:** DataFrame (rows and columns).\n\n**Import:**\n* import pandas as pd\n* data = pd.read_csv('data.csv')\n* data.head()\n\n\n","metadata":{}},{"id":"1b75a598-af4f-47f5-b704-8af5da266b5f","cell_type":"markdown","source":"### ğŸ“¦ Matplotlib\n\n- **Purpose:** Foundation plotting library in Python.  \n- **Logic:** Helps create static, publication-quality graphs.  \n- **Why We Use It:** For detailed control over plot design (titles, colors, labels).\n\n\n\n","metadata":{}},{"id":"ff45bb4d-35ae-4c14-8f31-ca5d118f98be","cell_type":"markdown","source":"### **ğŸ Explain the Seaborn library**\n\n**What:** A high-level Python visualization library built on Matplotlib, specialized for statistical graphics.\n\n**Why use it:** concise functions for complex plots, integrated with pandas DataFrames, sensible default aesthetics, and built-in support for plotting statistical summaries (means, confidence intervals, KDEs).\n\n**Fun fact:** Seabornâ€™s name comes from â€œSeaâ€ (as in Matplotlibâ€™s predecessor) + â€œbornâ€ â€” it was created to make statistical plotting prettier and easier.\n\n**Import:** \n\n* import seaborn as snsimport\n* matplotlib.pyplot as plt\n---","metadata":{}},{"id":"7d18e36a-0624-4bdf-9e07-ccdad01202da","cell_type":"markdown","source":"## ğŸ§© `Univariate Analysis for Categorical Data`\n\nWhen dealing with categorical variables, we analyze how many times each category appears to understand the distribution of categories.","metadata":{}},{"id":"910e3af3-e51a-42ed-92eb-ec7384807a5c","cell_type":"markdown","source":"### ğŸŸ¦ Count Plot\n\n- **Function:** sns.countplot()\n- **Purpose:** Displays the frequency of each category.\n- **Library:** Seaborn\n\n**Example:**\\\nsns.countplot(x='Category', data=data)\\\nplt.title(\"Count Plot of Category\")\\\nplt.show()\n\nğŸ§  **Insight**\n\nUseful for identifying dominant categories or class imbalance.","metadata":{}},{"id":"8a7b7c0a-6c2d-4a6e-ba53-aabf81837a93","cell_type":"markdown","source":"### ğŸŸ¨ Pie Chart\n\n- **Function:** plt.pie()\n- **Purpose:** Represents the proportion of each category as slices of a circle.\n- **Library:** Matplotlib\n\n**Example:**\\\ndata[].value_counts().plot.pie(autopct='', startangl=, cmap='')\\\nplt.title(\"\")\\\nplt.ylabel('')\\\nplt.show()\n\n**ğŸ’¡ Fun Fact**\n\nThe pie chart was first used in 1801 by William Playfair, known as the father of modern statistical graphics.\n\n---","metadata":{}},{"id":"4fe5ed60-3d5d-45b9-829a-0f0642ee4272","cell_type":"markdown","source":"## ğŸ“ `Univariate Analysis for Numerical Data`\n\nNow, we explore how to visualize numerical variables to understand their distribution, spread, and outliers.","metadata":{}},{"id":"3dbd9e9e-f317-45d4-8295-055f615ef64e","cell_type":"markdown","source":"### ğŸŸ¢ Histogram\n\n- **Function:** plt.hist() or sns.histplot()\n- **Purpose:** Shows the frequency distribution of numerical values.\n- **Library:** Matplotlib / Seaborn\n\n**Example:**\\\nsns.histplot(data[], bins=, kde=)\\\nplt.title(\"Histogram of Age\")\\\nplt.show()\n\n**ğŸ§  Insight**\n\nHelps identify whether the data is normally distributed or skewed.\n\n### ğŸ”µ Displot\n\n- **Function:**  sns.displot()\n- **Purpose:** Combines a histogram and KDE (Kernel Density Estimate) for a smoother distribution curve.\n- **Library:** Seaborn\n\n**Example:**\\\nsns.displot(data[], kde=, color='')\\\nplt.title(\"Displot of Salary Distribution\")\\\nplt.show()\n\n**ğŸ’¡ Fun Fact**\n\nKDE (Kernel Density Estimation) smooths the histogram curve to show the probability density of data.\n\n### ğŸŸ£ Box Plot\n\n- **Function:**  sns.boxplot()\n- **Purpose:** Displays data distribution, median, quartiles, and outliers.\n- **Library:** Seaborn\n\n**Example:**\\\nsns.boxplot(x=data[])\\\nplt.title(\"Box Plot of Income\")\\\nplt.show()\n\n**ğŸ§  Insight**\n\nIdeal for identifying outliers and understanding data spread (IQR â€” Interquartile Range).\n\n**ğŸ’¡ Fun Fact**\n\nThe box plot was invented by John Tukey in the 1970s â€” one of the pioneers of modern data visualization.\n\n### ğŸŒŸ Final Thought\n\n**â€œData tells a story â€” EDA is how we listen.â€**\n\nUnivariate Analysis is the foundation of data understanding before applying complex models.\nIt helps in cleaning, preprocessing, and making better data-driven decisions later.\n\n---","metadata":{}},{"id":"591beef7-48de-4e5b-9724-015651ec2c71","cell_type":"markdown","source":"## **`EDA â€” Bivariate & Multivariate Analysis`**\n\n","metadata":{}},{"id":"0241131d-8d81-4503-9bf4-0ca1f1ff7774","cell_type":"markdown","source":"### **ğŸ“˜ What is Bivariate & Multivariate EDA?**\n\n**Bivariate EDA:** Studying relationships between two variables (e.g., Age vs Salary).\n\n**Multivariate EDA:** Studying relationships among 3 or more variables simultaneously (e.g., Age, Salary, Department).\n\n**Why it matters:** Many ML models rely on relationships between features â€” bivariate/multivariate exploration reveals linearity, interactions, confounding, and grouping before modeling.\n\n**Fun fact:** Visualizing relationships early often exposes issues (like Simpsonâ€™s paradox) that simple univariate checks miss.","metadata":{}},{"id":"6d53ad23-0632-49d3-8503-d6b6b09fba56","cell_type":"markdown","source":"### **ğŸ“ˆ Scatter plot (Numerical â€” Numerical)**\n\n**What it shows:** points representing pairs of numeric values â€” good for spotting correlation, clusters, and outliers.\n\n**Seaborn function:** \n* sns.scatterplot()  \n* sns.relplot(kind=\"scatter\", ...)\n\n**When to use:** when both variables are continuous/numeric.\n\n**Insight:** look for linear/nonlinear trends, heteroscedasticity, and clusters.\n\n**Fun fact:** Scatter plots were popularized in the 19th century and remain one of the most direct ways to visualize correlation.","metadata":{}},{"id":"0dd06ab9-6967-45da-99f2-2b46390e593f","cell_type":"markdown","source":"### **ğŸ“Š Bar plot (Numerical â€” Categorical)**\n\n**What it shows:** summary statistic (mean, sum, etc.) of a numeric variable grouped by category. Useful to compare category-level averages.\n\n**Seaborn function:** \n* sns.barplot()\n\n**When to use:** categorical x-axis and numeric y-axis; to compare central tendency across categories.\n\n**Insight:** reveals group differences and potential categorical effects.\n\n**Fun fact:** Many bar plots in stats show a confidence interval by default in seaborn (use ci=None to remove).","metadata":{}},{"id":"91967d26-1f59-467c-9268-b320e8bbec40","cell_type":"markdown","source":"### **ğŸ“¦ Box plot (Numerical â€” Categorical)**\n\n**What it shows:** distribution summary (median, quartiles, whiskers, outliers) of a numeric variable per category.\n\n**Seaborn function:** \n* sns.boxplot()\n\n**When to use:** to compare spread and outliers across categories.\n\n**Insight:** great for spotting skew, spread differences, and category-specific outliers.\n\n**Fun fact:** The box plot (Tukey boxplot) was invented by John Tukey in the 1970s to succinctly show distribution summaries.","metadata":{}},{"id":"59801c7d-dfb6-4373-80b5-98b6c9375796","cell_type":"markdown","source":"### **ğŸ“‰ Distplot / Displot (Numerical â€” Categorical)**\n\n**What it shows:** histogram + KDE of numeric variable; when grouped by category, you can compare distributions across categories (via multiple plots or using hue).\n\n**Seaborn functions:** \n* sns.histplot() \n* sns.displot() (newer, figure-level)\n\n**When to use:** check modality (uni/bi-modal), skewness, and compare distributions between groups.\n\n**Insight:** overlapping KDEs quickly show where categories differ.\n\n**Fun fact:** KDE (kernel density estimation) produces a smooth estimate of the probability density â€” think of it as a smoothed histogram.","metadata":{}},{"id":"fa7fd5ed-00a1-4389-980d-52a2c09dd966","cell_type":"markdown","source":"### **ğŸ”¥ Heatmap (often Numerical â€” Numerical / CategoricalÃ—Categorical via crosstab)**\n\n**What it shows:** colored matrix representing values â€” commonly used for correlation matrices (numeric vs numeric) or frequency counts for categoricalÃ—categorical (via a crosstab).\n\n**Seaborn function:** \n* sns.heatmap()\n\n**When to use:** visualize pairwise correlations or joint frequency tables.\n\n**Insight:** heatmaps quickly show strong positive/negative correlations or hotspots in category intersections.\n\n**Fun fact:** Human brains detect color patterns faster than raw numbers â€” heatmaps exploit this for quick pattern spotting.","metadata":{}},{"id":"86a10ffe-fc35-4f25-b1a6-9941277a98b2","cell_type":"markdown","source":"### **ğŸŒ³ Clustermap (Hierarchical clustering of a matrix â€” often numeric matrix like correlations or counts)**\n\n**What it shows:** a heatmap with hierarchical clustering (dendrograms) to group similar rows/columns together â€” useful for discovering clusters in features or observations.\n\n**Seaborn function:** \n* sns.clustermap()\n\n**When to use:** exploratory grouping of variables or samples â€” especially in genomics, feature selection, or when you want to reorder a matrix by similarity.\n\n**Insight:** clusters reveal groups of similar variables or similar observations that merit further investigation.\n\n**Fun fact:** Clustermap combines heatmap + hierarchical clustering; itâ€™s often used in biological data analysis (e.g., gene expression).","metadata":{}},{"id":"153a0c05-0d43-4af4-83fb-baf7bfc1b6fa","cell_type":"markdown","source":"### **ğŸ”— Pairplot (Multivariate â€” overview of pairwise relationships)**\n\n**What it shows:** a matrix of plots: scatter plots for each numeric pair and histograms/KDEs on the diagonal â€” optionally colored by category (hue).\n\n**Seaborn function:** \n* sns.pairplot()\n\n**When to use:** quick multivariate check across many numeric features.\n\n**Insight:** spot pairwise correlations, cluster separation by class, and variable distributions at a glance.\n\n**Fun fact:** Pairplots are sometimes called â€œscatterplot matricesâ€ and are invaluable for quick feature vetting before modeling.","metadata":{}},{"id":"40971556-cf29-4935-b504-6d9ff434fb4e","cell_type":"markdown","source":"### **â– Line plot (numerical â€” numerical)**\n\n**What it shows:** relationship between numeric x and numeric y often used for time-series or ordered numeric x (e.g., Date vs Sales).\n\n**Seaborn function:** \n* sns.lineplot()\n\n**When to use:** time-series trends, continuous relationships, and to visualize smoothing/aggregates across x.\n\n**Insight:** lineplots make trends, seasonality, and abrupt changes obvious.\n\n**Fun fact:** When you add hue to sns.lineplot seaborn plots separate lines per category and by default shows confidence intervals for aggregated data.","metadata":{}},{"id":"7c9a36c9-df40-48ed-9c95-01b342953c4f","cell_type":"markdown","source":"### **âœ… Quick \"Which plot to use\" cheat-sheet**\n\n* Numerical â€” Numerical: Scatter, Line, Pairplot\n\n* Numerical â€” Categorical: Bar, Box, Violin, Displot (with hue/cols)\n\n* Categorical â€” Categorical: Crosstab + Heatmap, stacked bar\n\n* Multivariate overview: Pairplot, Clustermap, Heatmap (correlation)","metadata":{}},{"id":"f2ea8b24-d879-45fb-82c0-d414a223f51e","cell_type":"markdown","source":"### **ğŸ¯ Final tips**\n\n* Always start with pairwise visuals for many features, then zoom into specific bivariate plots.\n\n* Use hue, col, and row in seaborn to split plots by categories without manual grouping.\n\n* When overlaying distributions across categories, use common_norm=False or stat='density' to compare shapes fairly.","metadata":{}}]}