{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"eb03ad8a-3a34-4951-a4f0-02afc1c4d359","cell_type":"markdown","source":"# 🧠 `Understanding Your Data`\n\nBefore jumping into model building, one of the most critical stages in any machine learning project is **understanding your data**.  \nThis step lays the foundation for every decision that follows — from preprocessing and feature selection to model choice and evaluation.\n\n---\n\n## 🎯 Why Understanding Data Matters\n\nUnderstanding your dataset helps you:\n\n- Detect **data quality issues early** (missing values, duplicates, inconsistencies)  \n- Choose appropriate **feature engineering** and **modeling techniques**  \n- Avoid misleading results due to **data leakage or bias**  \n- Save time by identifying **irrelevant or redundant features** before training  \n\n💡 **Fact:** In real-world ML projects, data understanding and cleaning can take up to **60–80%** of total project time — because the quality of your data directly defines the quality of your model.\n\n---\n\n## 🔍 Key Questions to Ask About Your Data\n\nBelow are essential questions every ML engineer should ask before modeling — along with *why they matter*:\n\n---\n\n### 1️⃣ How big is the data?\n\n**Why it matters:** Dataset size determines which algorithms and validation methods are feasible.  \n**Insight:** A small dataset might require data augmentation or simpler models, while large datasets demand efficient storage, sampling, and computation strategies.\n\n---\n\n### 2️⃣ How does the data look?\n\n**Why it matters:** Viewing sample rows gives a sense of structure, column names, and potential anomalies.  \n**Action:** Use `.head()`, `.tail()`, or `.sample()` in Pandas to inspect random records.  \n**Fact:** Early visual inspection often reveals typos, inconsistent entries, or unexpected symbols.\n\n---\n\n### 3️⃣ What is the data type of each column?\n\n**Why it matters:** Correct data types (numeric, categorical, datetime, object) are crucial for preprocessing and model compatibility.  \n**Action:** Use `.info()` or `.dtypes` to check types and memory usage.  \n**Tip:** Convert datatypes carefully — wrong conversions can cause model errors or performance loss.\n\n---\n\n### 4️⃣ Are there any missing values?\n\n**Why it matters:** Missing data can bias results and reduce model accuracy.  \n**Action:** Use `.isnull().sum()` to find missing values.  \n**Solution:** Handle them using imputation (mean, median, mode), interpolation, or removal based on data context.\n\n---\n\n### 5️⃣ How does the data look mathematically?\n\n**Why it matters:** Understanding basic statistics helps detect outliers, skewness, or scaling issues.  \n**Action:** Use `.describe()` or visualizations (histograms, boxplots).  \n**Fact:** Skewed data may require transformation (e.g., log or power scaling) before model training.\n\n---\n\n### 6️⃣ Are there duplicate values?\n\n**Why it matters:** Duplicates inflate data and can bias models during training.  \n**Action:** Use `.duplicated().sum()` to check for them and remove using `.drop_duplicates()`.  \n**Fact:** Even small amounts of duplication can distort model metrics like accuracy or recall.\n\n---\n\n### 7️⃣ How is the correlation between columns?\n\n**Why it matters:** Highly correlated features can cause **multicollinearity**, confusing models and inflating variance.  \n**Action:** Use `.corr()` or heatmaps (Seaborn/Matplotlib) to visualize relationships.  \n**Tip:** Drop or combine highly correlated features to simplify the model.\n\n---\n\n## 📊 Summary\n\nUnderstanding your data is **not just an initial step** — it’s an **ongoing process** throughout model development.  \nIt ensures your insights are **trustworthy**, your features are **meaningful**, and your models are **robust**.\n\n> 🧩 **In short:** The better you know your data, the smarter your model will be.\n","metadata":{}},{"id":"d6233b25-1fd4-4b89-b8d2-f257de7f5bbf","cell_type":"markdown","source":"# 🧠 `Exploratory Data Analysis (EDA) using Univariate Analysis`\n\n---\n\n## 📊 Introduction to Data\n\nIn the world of **Data Science**, everything starts with **data**.  \nData is a **collection of facts and statistics** that can be analyzed to gain insights and make informed decisions.\n\nIn simple terms:\n **Data = Raw Information**\n\n### 🔹 Types of Data\n\nData is broadly divided into two main categories:\n\n1. **Numerical Data (Quantitative)**  \n   - Represents measurable quantities or numbers.  \n   - Example: Age, Salary, Temperature, Height.  \n   - Can be further divided into:\n     - **Continuous Data** → Values within a range (e.g., 5.3, 6.7)\n     - **Discrete Data** → Countable values (e.g., 1, 2, 3)\n\n2. **Categorical Data (Qualitative)**  \n   - Represents labels, groups, or categories.  \n   - Example: Gender (Male/Female), Country (USA, UK, Pakistan), Product Type (A, B, C)\n\n💡 **Fun Fact:**  \nOver 70% of the time in any Data Science project is spent **understanding, cleaning, and exploring data**, not modeling!\n\n---\n\n## 🔍 What is Univariate Analysis?\n\n**Univariate Analysis** means analyzing **one variable at a time**.  \nIt helps us **understand the pattern, distribution, and behavior** of individual features in the dataset.\n\n### 🎯 Purpose:\n- To summarize data.\n- To detect outliers or unusual patterns.\n- To decide which features may be useful for modeling.\n\n### ⚙️ How we do it:\n- For **Numerical Data** → we use plots like **histogram**, **box plot**, **displot**, etc.  \n- For **Categorical Data** → we use **count plots**, **bar charts**, or **pie charts**.\n\n💡 **Fun Fact:**  \nThe word *“Univariate”* comes from “Uni” meaning one, and “Variate” meaning variable — literally \"one variable analysis\"!\n\n---\n\n## `🧰 Libraries Commonly Used in EDA`\n\nBefore jumping into plots, let’s discuss the libraries that help us perform EDA effectively.\n\n### 📦 `pandas`\n- **Purpose:** Used for data manipulation and analysis.\n- **Logic:** Think of it as Excel in Python — it allows you to read, clean, and explore data easily.\n- **Key Structure:** DataFrame (rows and columns).\n\n**Import:**\n* import pandas as pd\n* data = pd.read_csv('data.csv')\n* data.head()\n\n\n","metadata":{}},{"id":"1b75a598-af4f-47f5-b704-8af5da266b5f","cell_type":"markdown","source":"### 📦 Matplotlib\n\n- **Purpose:** Foundation plotting library in Python.  \n- **Logic:** Helps create static, publication-quality graphs.  \n- **Why We Use It:** For detailed control over plot design (titles, colors, labels).\n\n\n\n","metadata":{}},{"id":"ff45bb4d-35ae-4c14-8f31-ca5d118f98be","cell_type":"markdown","source":"### **🐍 Explain the Seaborn library**\n\n**What:** A high-level Python visualization library built on Matplotlib, specialized for statistical graphics.\n\n**Why use it:** concise functions for complex plots, integrated with pandas DataFrames, sensible default aesthetics, and built-in support for plotting statistical summaries (means, confidence intervals, KDEs).\n\n**Fun fact:** Seaborn’s name comes from “Sea” (as in Matplotlib’s predecessor) + “born” — it was created to make statistical plotting prettier and easier.\n\n**Import:** \n\n* import seaborn as snsimport\n* matplotlib.pyplot as plt\n---","metadata":{}},{"id":"7d18e36a-0624-4bdf-9e07-ccdad01202da","cell_type":"markdown","source":"## 🧩 `Univariate Analysis for Categorical Data`\n\nWhen dealing with categorical variables, we analyze how many times each category appears to understand the distribution of categories.","metadata":{}},{"id":"910e3af3-e51a-42ed-92eb-ec7384807a5c","cell_type":"markdown","source":"### 🟦 Count Plot\n\n- **Function:** sns.countplot()\n- **Purpose:** Displays the frequency of each category.\n- **Library:** Seaborn\n\n**Example:**\\\nsns.countplot(x='Category', data=data)\\\nplt.title(\"Count Plot of Category\")\\\nplt.show()\n\n🧠 **Insight**\n\nUseful for identifying dominant categories or class imbalance.","metadata":{}},{"id":"8a7b7c0a-6c2d-4a6e-ba53-aabf81837a93","cell_type":"markdown","source":"### 🟨 Pie Chart\n\n- **Function:** plt.pie()\n- **Purpose:** Represents the proportion of each category as slices of a circle.\n- **Library:** Matplotlib\n\n**Example:**\\\ndata[].value_counts().plot.pie(autopct='', startangl=, cmap='')\\\nplt.title(\"\")\\\nplt.ylabel('')\\\nplt.show()\n\n**💡 Fun Fact**\n\nThe pie chart was first used in 1801 by William Playfair, known as the father of modern statistical graphics.\n\n---","metadata":{}},{"id":"4fe5ed60-3d5d-45b9-829a-0f0642ee4272","cell_type":"markdown","source":"## 📏 `Univariate Analysis for Numerical Data`\n\nNow, we explore how to visualize numerical variables to understand their distribution, spread, and outliers.","metadata":{}},{"id":"3dbd9e9e-f317-45d4-8295-055f615ef64e","cell_type":"markdown","source":"### 🟢 Histogram\n\n- **Function:** plt.hist() or sns.histplot()\n- **Purpose:** Shows the frequency distribution of numerical values.\n- **Library:** Matplotlib / Seaborn\n\n**Example:**\\\nsns.histplot(data[], bins=, kde=)\\\nplt.title(\"Histogram of Age\")\\\nplt.show()\n\n**🧠 Insight**\n\nHelps identify whether the data is normally distributed or skewed.\n\n### 🔵 Displot\n\n- **Function:**  sns.displot()\n- **Purpose:** Combines a histogram and KDE (Kernel Density Estimate) for a smoother distribution curve.\n- **Library:** Seaborn\n\n**Example:**\\\nsns.displot(data[], kde=, color='')\\\nplt.title(\"Displot of Salary Distribution\")\\\nplt.show()\n\n**💡 Fun Fact**\n\nKDE (Kernel Density Estimation) smooths the histogram curve to show the probability density of data.\n\n### 🟣 Box Plot\n\n- **Function:**  sns.boxplot()\n- **Purpose:** Displays data distribution, median, quartiles, and outliers.\n- **Library:** Seaborn\n\n**Example:**\\\nsns.boxplot(x=data[])\\\nplt.title(\"Box Plot of Income\")\\\nplt.show()\n\n**🧠 Insight**\n\nIdeal for identifying outliers and understanding data spread (IQR — Interquartile Range).\n\n**💡 Fun Fact**\n\nThe box plot was invented by John Tukey in the 1970s — one of the pioneers of modern data visualization.\n\n### 🌟 Final Thought\n\n**“Data tells a story — EDA is how we listen.”**\n\nUnivariate Analysis is the foundation of data understanding before applying complex models.\nIt helps in cleaning, preprocessing, and making better data-driven decisions later.\n\n---","metadata":{}},{"id":"591beef7-48de-4e5b-9724-015651ec2c71","cell_type":"markdown","source":"## **`EDA — Bivariate & Multivariate Analysis`**\n\n","metadata":{}},{"id":"0241131d-8d81-4503-9bf4-0ca1f1ff7774","cell_type":"markdown","source":"### **📘 What is Bivariate & Multivariate EDA?**\n\n**Bivariate EDA:** Studying relationships between two variables (e.g., Age vs Salary).\n\n**Multivariate EDA:** Studying relationships among 3 or more variables simultaneously (e.g., Age, Salary, Department).\n\n**Why it matters:** Many ML models rely on relationships between features — bivariate/multivariate exploration reveals linearity, interactions, confounding, and grouping before modeling.\n\n**Fun fact:** Visualizing relationships early often exposes issues (like Simpson’s paradox) that simple univariate checks miss.","metadata":{}},{"id":"6d53ad23-0632-49d3-8503-d6b6b09fba56","cell_type":"markdown","source":"### **📈 Scatter plot (Numerical — Numerical)**\n\n**What it shows:** points representing pairs of numeric values — good for spotting correlation, clusters, and outliers.\n\n**Seaborn function:** \n* sns.scatterplot()  \n* sns.relplot(kind=\"scatter\", ...)\n\n**When to use:** when both variables are continuous/numeric.\n\n**Insight:** look for linear/nonlinear trends, heteroscedasticity, and clusters.\n\n**Fun fact:** Scatter plots were popularized in the 19th century and remain one of the most direct ways to visualize correlation.","metadata":{}},{"id":"0dd06ab9-6967-45da-99f2-2b46390e593f","cell_type":"markdown","source":"### **📊 Bar plot (Numerical — Categorical)**\n\n**What it shows:** summary statistic (mean, sum, etc.) of a numeric variable grouped by category. Useful to compare category-level averages.\n\n**Seaborn function:** \n* sns.barplot()\n\n**When to use:** categorical x-axis and numeric y-axis; to compare central tendency across categories.\n\n**Insight:** reveals group differences and potential categorical effects.\n\n**Fun fact:** Many bar plots in stats show a confidence interval by default in seaborn (use ci=None to remove).","metadata":{}},{"id":"91967d26-1f59-467c-9268-b320e8bbec40","cell_type":"markdown","source":"### **📦 Box plot (Numerical — Categorical)**\n\n**What it shows:** distribution summary (median, quartiles, whiskers, outliers) of a numeric variable per category.\n\n**Seaborn function:** \n* sns.boxplot()\n\n**When to use:** to compare spread and outliers across categories.\n\n**Insight:** great for spotting skew, spread differences, and category-specific outliers.\n\n**Fun fact:** The box plot (Tukey boxplot) was invented by John Tukey in the 1970s to succinctly show distribution summaries.","metadata":{}},{"id":"59801c7d-dfb6-4373-80b5-98b6c9375796","cell_type":"markdown","source":"### **📉 Distplot / Displot (Numerical — Categorical)**\n\n**What it shows:** histogram + KDE of numeric variable; when grouped by category, you can compare distributions across categories (via multiple plots or using hue).\n\n**Seaborn functions:** \n* sns.histplot() \n* sns.displot() (newer, figure-level)\n\n**When to use:** check modality (uni/bi-modal), skewness, and compare distributions between groups.\n\n**Insight:** overlapping KDEs quickly show where categories differ.\n\n**Fun fact:** KDE (kernel density estimation) produces a smooth estimate of the probability density — think of it as a smoothed histogram.","metadata":{}},{"id":"fa7fd5ed-00a1-4389-980d-52a2c09dd966","cell_type":"markdown","source":"### **🔥 Heatmap (often Numerical — Numerical / Categorical×Categorical via crosstab)**\n\n**What it shows:** colored matrix representing values — commonly used for correlation matrices (numeric vs numeric) or frequency counts for categorical×categorical (via a crosstab).\n\n**Seaborn function:** \n* sns.heatmap()\n\n**When to use:** visualize pairwise correlations or joint frequency tables.\n\n**Insight:** heatmaps quickly show strong positive/negative correlations or hotspots in category intersections.\n\n**Fun fact:** Human brains detect color patterns faster than raw numbers — heatmaps exploit this for quick pattern spotting.","metadata":{}},{"id":"86a10ffe-fc35-4f25-b1a6-9941277a98b2","cell_type":"markdown","source":"### **🌳 Clustermap (Hierarchical clustering of a matrix — often numeric matrix like correlations or counts)**\n\n**What it shows:** a heatmap with hierarchical clustering (dendrograms) to group similar rows/columns together — useful for discovering clusters in features or observations.\n\n**Seaborn function:** \n* sns.clustermap()\n\n**When to use:** exploratory grouping of variables or samples — especially in genomics, feature selection, or when you want to reorder a matrix by similarity.\n\n**Insight:** clusters reveal groups of similar variables or similar observations that merit further investigation.\n\n**Fun fact:** Clustermap combines heatmap + hierarchical clustering; it’s often used in biological data analysis (e.g., gene expression).","metadata":{}},{"id":"153a0c05-0d43-4af4-83fb-baf7bfc1b6fa","cell_type":"markdown","source":"### **🔗 Pairplot (Multivariate — overview of pairwise relationships)**\n\n**What it shows:** a matrix of plots: scatter plots for each numeric pair and histograms/KDEs on the diagonal — optionally colored by category (hue).\n\n**Seaborn function:** \n* sns.pairplot()\n\n**When to use:** quick multivariate check across many numeric features.\n\n**Insight:** spot pairwise correlations, cluster separation by class, and variable distributions at a glance.\n\n**Fun fact:** Pairplots are sometimes called “scatterplot matrices” and are invaluable for quick feature vetting before modeling.","metadata":{}},{"id":"40971556-cf29-4935-b504-6d9ff434fb4e","cell_type":"markdown","source":"### **➖ Line plot (numerical — numerical)**\n\n**What it shows:** relationship between numeric x and numeric y often used for time-series or ordered numeric x (e.g., Date vs Sales).\n\n**Seaborn function:** \n* sns.lineplot()\n\n**When to use:** time-series trends, continuous relationships, and to visualize smoothing/aggregates across x.\n\n**Insight:** lineplots make trends, seasonality, and abrupt changes obvious.\n\n**Fun fact:** When you add hue to sns.lineplot seaborn plots separate lines per category and by default shows confidence intervals for aggregated data.","metadata":{}},{"id":"7c9a36c9-df40-48ed-9c95-01b342953c4f","cell_type":"markdown","source":"### **✅ Quick \"Which plot to use\" cheat-sheet**\n\n* Numerical — Numerical: Scatter, Line, Pairplot\n\n* Numerical — Categorical: Bar, Box, Violin, Displot (with hue/cols)\n\n* Categorical — Categorical: Crosstab + Heatmap, stacked bar\n\n* Multivariate overview: Pairplot, Clustermap, Heatmap (correlation)","metadata":{}},{"id":"f2ea8b24-d879-45fb-82c0-d414a223f51e","cell_type":"markdown","source":"### **🎯 Final tips**\n\n* Always start with pairwise visuals for many features, then zoom into specific bivariate plots.\n\n* Use hue, col, and row in seaborn to split plots by categories without manual grouping.\n\n* When overlaying distributions across categories, use common_norm=False or stat='density' to compare shapes fairly.","metadata":{}}]}